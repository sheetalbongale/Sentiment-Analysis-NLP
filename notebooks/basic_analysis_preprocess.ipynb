{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the text files in a Python list\n",
    "reviews_train = []\n",
    "for line in open('data/full_test.txt', 'r'):\n",
    "    \n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open('data/full_test.txt', 'r'):\n",
    "    \n",
    "    reviews_test.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I saw this film on September 1st, 2005 in Indianapolis. I am one of the judges for the Heartland Film Festival that screens films for their Truly Moving Picture Award. A Truly Moving Picture \"...explores the human journey by artistically expressing hope and respect for the positive values of life.\" Heartland gave that award to this film.<br /><br />This is a story of golf in the early part of the 20th century. At that time, it was the game of upper class and rich \"gentlemen\", and working people could only participate by being caddies at country clubs. With this backdrop, this based-on-a-true-story unfolds with a young, working class boy who takes on the golf establishment and the greatest golfer in the world, Harry Vardon.<br /><br />And the story is inspirational. Against all odds, Francis Ouimet (played by Shia LaBeouf of \"Holes\") gets to compete against the greatest golfers of the U.S. and Great Britain at the 1913 U.S. Open. Francis is ill-prepared, and has a child for a caddy. (The caddy is hilarious and motivational and steals every scene he appears in.) But despite these handicaps, Francis displays courage, spirit, heroism, and humility at this world class event.<br /><br />And, we learn a lot about the early years of golf; for example, the use of small wooden clubs, the layout of the short holes, the manual scoreboard, the golfers swinging with pipes in their mouths, the terrible conditions of the greens and fairways, and the play not being canceled even in torrential rain.<br /><br />This film has stunning cinematography and art direction and editing. And with no big movie stars, the story is somehow more believable.<br /><br />This adds to the inventory of great sports movies in the vein of \"Miracle\" and \"Remember the Titans.\"<br /><br />FYI - There is a Truly Moving Pictures web site where there is a listing of past winners going back 70 years.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Pre-Processing\n",
    "Using regular expressions to clean the raw text that is messy for further analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regex\n",
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i saw this film on september st  in indianapolis i am one of the judges for the heartland film festival that screens films for their truly moving picture award a truly moving picture explores the human journey by artistically expressing hope and respect for the positive values of life heartland gave that award to this film this is a story of golf in the early part of the th century at that time it was the game of upper class and rich gentlemen and working people could only participate by being caddies at country clubs with this backdrop this based on a true story unfolds with a young working class boy who takes on the golf establishment and the greatest golfer in the world harry vardon and the story is inspirational against all odds francis ouimet played by shia labeouf of holes gets to compete against the greatest golfers of the us and great britain at the  us open francis is ill prepared and has a child for a caddy the caddy is hilarious and motivational and steals every scene he appears in but despite these handicaps francis displays courage spirit heroism and humility at this world class event and we learn a lot about the early years of golf for example the use of small wooden clubs the layout of the short holes the manual scoreboard the golfers swinging with pipes in their mouths the terrible conditions of the greens and fairways and the play not being canceled even in torrential rain this film has stunning cinematography and art direction and editing and with no big movie stars the story is somehow more believable this adds to the inventory of great sports movies in the vein of miracle and remember the titans fyi   there is a truly moving pictures web site where there is a listing of past winners going back  years'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_clean[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "In order for this data to make sense to our machine learning algorithm we’ll need to convert each review to a numeric representation, which we call **vectorization**.\n",
    "The simplest form of this is to create one very large matrix with one column for every unique word in your corpus (where the corpus is all 50k reviews in our case). Then we transform each review into one row containing 0s and 1s, where 1 means that the word in the corpus corresponding to that column appears in that review. That being said, each row of the matrix will be very sparse (mostly zeros). This process is also known as **one hot encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classifier\n",
    "Now that we’ve transformed our dataset into a format suitable for modeling we can start building a classifier. \n",
    "\n",
    "Logistic Regression is a good baseline model for us to use for several reasons: \n",
    "- They’re easy to interpret, \n",
    "- linear models tend to perform well on sparse datasets like this one, and \n",
    "- they learn very fast compared to other algorithms.\n",
    "To keep things simple I’m only going to worry about the hyperparameter C, which adjusts the regularization.\n",
    "\n",
    "Note: The targets/labels we use will be the same for training and testing because both datasets are structured the same, where the first 12.5k are positive and the last 12.5k are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87408\n",
      "Accuracy for C=0.05: 0.8848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sheetalbongale/.local/share/virtualenvs/Fish-Weight-Estimation-Linear-Regression-KWFFYgbH/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.25: 0.88896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sheetalbongale/.local/share/virtualenvs/Fish-Weight-Estimation-Linear-Regression-KWFFYgbH/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.5: 0.88928\n",
      "Accuracy for C=1: 0.8872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sheetalbongale/.local/share/virtualenvs/Fish-Weight-Estimation-Linear-Regression-KWFFYgbH/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "#     Accuracy for C=0.01: 0.87472\n",
    "#     Accuracy for C=0.05: 0.88368\n",
    "#     Accuracy for C=0.25: 0.88016\n",
    "#     Accuracy for C=0.5: 0.87808\n",
    "#     Accuracy for C=1: 0.87648"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.9532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sheetalbongale/.local/share/virtualenvs/Fish-Weight-Estimation-Linear-Regression-KWFFYgbH/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.05)\n",
    "final_model.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_model.predict(X_test)))\n",
    "# Final Accuracy: 0.88128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Check\n",
    "Let’s look at the 5 most discriminating words for both positive and negative reviews. \n",
    "\n",
    "We’ll do this by looking at the largest and smallest coefficients, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 0.9288812418118644)\n",
      "('perfect', 0.7934641227980576)\n",
      "('great', 0.675040909917553)\n",
      "('amazing', 0.6160398142631545)\n",
      "('superb', 0.6063967799425831)\n",
      "('worst', -1.367978497228895)\n",
      "('waste', -1.1684451288279047)\n",
      "('awful', -1.0277001734353677)\n",
      "('poorly', -0.8748317895742782)\n",
      "('boring', -0.8587249740682945)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "    \n",
    "#     ('excellent', 0.9288812418118644)\n",
    "#     ('perfect', 0.7934641227980576)\n",
    "#     ('great', 0.675040909917553)\n",
    "#     ('amazing', 0.6160398142631545)\n",
    "#     ('superb', 0.6063967799425831)\n",
    "    \n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)\n",
    "    \n",
    "#     ('worst', -1.367978497228895)\n",
    "#     ('waste', -1.1684451288279047)\n",
    "#     ('awful', -1.0277001734353677)\n",
    "#     ('poorly', -0.8748317895742782)\n",
    "#     ('boring', -0.8587249740682945)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
